{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mappable Data Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this notebook, you are able to enter an address and run the notebook from start to finish. At the end, it will save a CSV as final_data.csv in the Data folder that can be used in a Tableau workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import jsonpickle\n",
    "import json\n",
    "import datetime\n",
    "import config\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from pandas.io.json import json_normalize\n",
    "import regex as re\n",
    "import pickle\n",
    "import json, requests\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings; warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = '520 Ashe Ave Raleigh, NC '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter API Verification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'ghLI1MRdoZwrzxbvgNcO6Bzok'\n",
    "consumer_secret = '6A0VY7ARyjCMEdKxKTVwSRPyTxpvzhLx8wUnpQOdzK3ISTll08'\n",
    "access_token = '15875126-n7JhBGP8efifn1SqHeVQtwjtOxpKDh5CAGcdjg1sF'\n",
    "access_token_secret = 'Ny9UPPXVEIou8HgwpN3hyiZYKTX1Fns3fQ9OhnQAgFPoy'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Neumann\n"
     ]
    }
   ],
   "source": [
    "user = api.me()\n",
    "print (user.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address Search\n",
    "\n",
    "The below code searches for your address on mapdevelopers.com and returns both the geolocation coordinates and the upper left and lower right corners of a bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run selenium webdriver to search for address and return latitude and longitude (turn this into a function)\n",
    "def find_address(address):\n",
    "    #establish driver and URL\n",
    "    driver = webdriver.Chrome(executable_path='./chromedriver 2')\n",
    "    url = 'https://www.mapdevelopers.com/geocode_tool.php'\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "    #fill in address and click button\n",
    "    address_field = driver.find_element_by_id(\"address\")\n",
    "    address_field.send_keys(address)\n",
    "    search_button = driver.find_element_by_xpath('//*[@id=\"search-form\"]/div[1]/span[2]/button')\n",
    "    search_button.click()\n",
    "    #set up \n",
    "    html= driver.page_source\n",
    "    time.sleep(10)\n",
    "    html= driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    location = (soup.find('div', {'id':\"display_lat\"}).text, soup.find('div', {'id':\"display_lng\"}).text)    \n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude, longitude = find_address(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_left = (str(float(latitude)+.36)+ ','+ str(float(longitude)+.36))\n",
    "bottom_right = (str(float(latitude)-.36) + ','+str(float(longitude)-.36))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for live tweets\n",
    "\n",
    "The below code pulls in tweets from the past 24 hours, and returns only tweets with geolocation data attached in a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = datetime.datetime.now().year\n",
    "month = datetime.datetime.now().month\n",
    "day = datetime.datetime.now().day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(search_terms = \"\"):\n",
    "    tweet_id = []\n",
    "    tweet_time = []\n",
    "    tweet_text = []\n",
    "    tweet_coordinates = []\n",
    "    tweet_place = []\n",
    "    tweet_count = 0\n",
    "    tweet_dataframe = pd.DataFrame()\n",
    "    for tweet in tweepy.Cursor(api.search,\n",
    "                               q=search_terms,\n",
    "                               geocode =f'{latitude},{longitude},25mi',\n",
    "                               since = f'{year}-{month}-{day-1}',\n",
    "                               rpp=100,\n",
    "                               result_type=\"recent\",\n",
    "                               include_entities=True,).items(1000):\n",
    "        if tweet.coordinates != None or tweet.place !=None: \n",
    "            tweet_id.append(tweet.id_str)\n",
    "            tweet_time.append(tweet.created_at)\n",
    "            tweet_text.append(tweet.text)\n",
    "            tweet_coordinates.append(tweet.coordinates)\n",
    "            tweet_place.append(tweet.place)\n",
    "            tweet_count += 1\n",
    "        else:\n",
    "            pass\n",
    "    tweet_dataframe['id'] = tweet_id\n",
    "    tweet_dataframe['time'] = tweet_time\n",
    "    tweet_dataframe['text'] = tweet_text\n",
    "    tweet_dataframe['coordinates'] =tweet_coordinates\n",
    "    tweet_dataframe['place'] = tweet_place\n",
    "    \n",
    "    print(tweet_count)\n",
    "    return tweet_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = ['road closed', \"road closure\", 'intersection blocked', \n",
    "                'blocked road', 'flooded road', \"closed due to road\",\n",
    "               'intersection closed', 'highway closed', 'hwy closed',\n",
    "               'street closed', 'street flooded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframe = pd.DataFrame(columns = ['id', 'time', 'text', 'coordinates', 'place'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "6\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1122660982860525569</td>\n",
       "      <td>2019-04-29 00:36:51</td>\n",
       "      <td>@mattbman @CanesandCoffee They have it blocked...</td>\n",
       "      <td>None</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x11ba5e7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1122622172000919553</td>\n",
       "      <td>2019-04-28 22:02:37</td>\n",
       "      <td>Ramp to miami blvd closed til the end of july ...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-78.85817, 3...</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x11ba5e7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1122622170969014272</td>\n",
       "      <td>2019-04-28 22:02:37</td>\n",
       "      <td>Various lanes closed for overnight constructio...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-78.86296, 3...</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x11ba5e7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1122622160042852352</td>\n",
       "      <td>2019-04-28 22:02:34</td>\n",
       "      <td>Closed around the clock for construction til t...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-78.90279, 3...</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x11ba5e7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1122328007945986048</td>\n",
       "      <td>2019-04-28 02:33:43</td>\n",
       "      <td>Closed around the clock for construction til t...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-78.90279, 3...</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x11ba5e7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                time  \\\n",
       "0  1122660982860525569 2019-04-29 00:36:51   \n",
       "0  1122622172000919553 2019-04-28 22:02:37   \n",
       "1  1122622170969014272 2019-04-28 22:02:37   \n",
       "2  1122622160042852352 2019-04-28 22:02:34   \n",
       "3  1122328007945986048 2019-04-28 02:33:43   \n",
       "\n",
       "                                                text  \\\n",
       "0  @mattbman @CanesandCoffee They have it blocked...   \n",
       "0  Ramp to miami blvd closed til the end of july ...   \n",
       "1  Various lanes closed for overnight constructio...   \n",
       "2  Closed around the clock for construction til t...   \n",
       "3  Closed around the clock for construction til t...   \n",
       "\n",
       "                                         coordinates  \\\n",
       "0                                               None   \n",
       "0  {'type': 'Point', 'coordinates': [-78.85817, 3...   \n",
       "1  {'type': 'Point', 'coordinates': [-78.86296, 3...   \n",
       "2  {'type': 'Point', 'coordinates': [-78.90279, 3...   \n",
       "3  {'type': 'Point', 'coordinates': [-78.90279, 3...   \n",
       "\n",
       "                                               place  \n",
       "0  Place(_api=<tweepy.api.API object at 0x11ba5e7...  \n",
       "0  Place(_api=<tweepy.api.API object at 0x11ba5e7...  \n",
       "1  Place(_api=<tweepy.api.API object at 0x11ba5e7...  \n",
       "2  Place(_api=<tweepy.api.API object at 0x11ba5e7...  \n",
       "3  Place(_api=<tweepy.api.API object at 0x11ba5e7...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for term in search_terms:\n",
    "    df = get_tweets(term)\n",
    "    raw_dataframe = raw_dataframe.append(df)\n",
    "    \n",
    "raw_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean data and run through deepa's model\n",
    "data = raw_dataframe.drop_duplicates(subset='text')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean data according to final modeling notbook\n",
    "data = data.drop_duplicates(subset='text')\n",
    "data['text'] = [i.lower() for i in data['text']]\n",
    "data['text'] = [re.sub(r'@[A-z0-9]*', r' ', i) \n",
    "                    for i in data['text']];\n",
    "data['text'] = [re.sub('[^A-Za-z0-9#]+', ' ', i) \n",
    "                    for i in data['text']];\n",
    "lm = WordNetLemmatizer()\n",
    "data['text'] = [\" \".join([lm.lemmatize(w) for w in i.split()]) \n",
    "                   for i in data['text']];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import final model to read tweets using Pickle:\n",
    "rating_model = pickle.load(open('../gb_model.sav', 'rb'))\n",
    "tvec = pickle.load(open('../tvec.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_text = tvec.transform(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ratings'] = rating_model.predict(transformed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "Name: ratings, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ratings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out any lane closures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list1 = ['road', 'street','rd', 'hwy', 'highway', 'ave', 'avenue','intersection']\n",
    "word_list2 = ['closed','closure', 'blocked', 'flooded']\n",
    "not_word_list = ['lane closed', 'lane closure','cleared', 're opened', 'reopen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_road_closure'] = data['text'].map(lambda x: 1 if ((any(word in x for word in word_list1))\n",
    "                                                           & (any(word in x for word in word_list2))\n",
    "                                                           & (not any(word in x for word in not_word_list))\n",
    "                                                          ) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe for next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt_to_map = data[(data['ratings']==1) & (data['is_road_closure'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Easily mappable tweets to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns without exact coordinates\n",
    "map_first = attempt_to_map.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull out longitude and latitude, and modify data to be in final dataframe format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_first[ 'LONGITUDE'] = [point['coordinates'][0] for point in map_first['coordinates']]\n",
    "map_first['LATITUDE'] = [point['coordinates'][1] for point in map_first['coordinates']]\n",
    "map_first['start_end'] = ['Twitter' for i in map_first['ratings']]\n",
    "map_first['incident'] = map_first['time'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mapping_df = map_first[['LATITUDE', 'LONGITUDE', 'start_end', 'incident']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse remaining tweets for mappable intersections\n",
    "\n",
    "As explained in our project documentation, we did not execute code parsing the tweets, as we were unable to generalize it to read tweets written by normal twitter users. For future use, the other tweets can be found in the below dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_second = attempt_to_map[attempt_to_map['coordinates'].isna()]\n",
    "map_second.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull HERE.com data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set app_id and code\n",
    "YOUR_APP_ID= '7XoonMBoPg2xPSOtvXaC'\n",
    "YOUR_APP_CODE= 'zUzHm_f3ixL9EefzlBknuQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://traffic.api.here.com/traffic/6.3/incidents.json?app_id=7XoonMBoPg2xPSOtvXaC&app_code=zUzHm_f3ixL9EefzlBknuQ&bbox=36.1386471,-78.3029628;35.4186471,-79.0229628&criticality=critical'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f'https://traffic.api.here.com/traffic/6.3/incidents.json?app_id={YOUR_APP_ID}&app_code={YOUR_APP_CODE}&bbox={top_left};{bottom_right}&criticality=critical'\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14:24'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get(url)\n",
    "date_requested = time.strftime('%Y-%m-%d')\n",
    "time_requested = time.strftime('%H:%M') # 24-hour format\n",
    "date_requested; time_requested\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using methods written out in the HERE.com data cleaning notebook, append the final_mapping_df with live traffic data streamed from HERE.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 4)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmaps_json = res.json()\n",
    "incidents = pd.DataFrame(hmaps_json['TRAFFIC_ITEMS']['TRAFFIC_ITEM'])\n",
    "incidents = incidents.drop(axis=1, columns=['ABBREVIATION', 'ORIGINAL_TRAFFIC_ITEM_ID', 'PRODUCT',\n",
    "                                              'TRAFFIC_ITEM_ID', 'mid'])\n",
    "incidents.rename(str.lower, axis=1, inplace=True)\n",
    "locations = pd.DataFrame(list(incidents['location']))\n",
    "locations.rename(str.lower, axis=1, inplace=True)\n",
    "locations = locations.applymap(lambda x: {} if pd.isnull(x) else x)\n",
    "loc_coord = pd.DataFrame(list(locations['geoloc']))\n",
    "loc_coord.rename(str.lower, axis=1, inplace=True)\n",
    "origin = loc_coord['origin'].apply(pd.Series)\n",
    "origin['start_end'] = 'start'\n",
    "origin['incident'] = origin.index\n",
    "to = pd.DataFrame(s for k, v in loc_coord['to'].items() for s in v)\n",
    "to['start_end'] = 'end'\n",
    "to['incident'] = to.index\n",
    "all_locations = pd.concat((origin, to), axis=0)\n",
    "all_locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mapping_df = final_mapping_df.append(all_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export final data to CSV!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mapping_df.to_csv('../data/final_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
